from typing import AsyncGenerator, List, Optional
import aiohttp
from metagpt.configs.llm_config import LLMConfig
from metagpt.provider.base_llm import BaseLLM
from metagpt.schema import Message

class CustomLLMConfig(LLMConfig):
    api_endpoint: str
    api_key: str
    model: str = "custom-model"
    temperature: float = 0.7
    max_tokens: int = 2048

class CustomLLM(BaseLLM):
    def __init__(self, config: CustomLLMConfig):
        super().__init__()
        self.config = config
        # Initialize your client here

    async def _aask(self, prompt: str, timeout: int = 3) -> str:
        messages = [Message(role="user", content=prompt)]
        return await self._achat(messages, timeout=timeout)

    async def _achat(self, messages: List[Message], timeout: int = 3) -> str:
        formatted = [{"role": msg.role, "content": msg.content} for msg in messages]
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                self.config.api_endpoint,
                headers={"Authorization": f"Bearer {self.config.api_key}"},
                json={
                    "messages": formatted,
                    "temperature": self.config.temperature,
                    "max_tokens": self.config.max_tokens
                },
                timeout=timeout
            ) as response:
                response.raise_for_status()
                data = await response.json()
                return data["choices"][0]["message"]["content"]

    async def _acompletion_text(self, prompt: str, stream: bool = False, timeout: int = 3) -> AsyncGenerator:
        response = await self._aask(prompt, timeout)
        yield response
